{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data_cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(sparse_columns, varlen_sparse_columns, embed_dim,\n",
    "                            init_std=0.0001, padding=True, device='cpu', mode='mean'):\n",
    "    # sparse_columns => dict{'name':vocab_size}\n",
    "    # Return nn.ModuleDict: for sparse features, {embedding_name: nn.Embedding}\n",
    "    padding_idx = 0 if padding else None\n",
    "    sparse_embedding_dict = {\n",
    "        feat: nn.Embedding(sparse_columns[feat], embed_dim, padding_idx=padding_idx)\n",
    "                             for feat in sparse_columns\n",
    "    }\n",
    "    \n",
    "    if varlen_sparse_columns:\n",
    "        varlen_sparse_embedding_dict = {\n",
    "            feat:nn.EmbeddingBag(varlen_sparse_columns[feat], embed_dim, padding_idx=padding_idx,\n",
    "                                 mode=mode) for feat in varlen_sparse_columns\n",
    "        }\n",
    "        sparse_embedding_dict.update(varlen_sparse_embedding_dict)\n",
    "        \n",
    "    embedding_dict = nn.ModuleDict(sparse_embedding_dict)\n",
    "    \n",
    "    for tensor in embedding_dict.values():\n",
    "        nn.init.normal_(tensor.weight, mean=0, std=init_std)\n",
    "        # nn.init.kaiming_uniform_(tensor.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    return embedding_dict.to(device)\n",
    "\n",
    "\n",
    "class EGES(nn.Module):\n",
    "    def __init__(self, sparse_dict, varlen_sparse_dict=None, target_col='sku_id',\n",
    "                 n_embed=64, k_side=3, noise_dist=None, device='cpu', padding=True):\n",
    "        \"\"\"sparse_dict: dict, {feature_name: vocab_size}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_embed = n_embed\n",
    "        self.k_side = k_side\n",
    "        self.device = device\n",
    "        self.padding = padding\n",
    "        self.target_col = target_col\n",
    "        self.features = list(sparse_dict.keys())\n",
    "        if varlen_sparse_dict:\n",
    "            self.features = self.features + list(varlen_sparse_dict.keys())\n",
    "        # 如果padding了的话，则负采样出来的index均需要+1\n",
    "        self.sample_word_offset = 1 if padding else 0\n",
    "        # input embedding dict, include item and side info\n",
    "        self.input_embedding_dict = create_embedding_matrix(\n",
    "            sparse_dict, varlen_sparse_dict, n_embed,\n",
    "            init_std=0.0001, padding=padding, device=device, mode='mean')\n",
    "        self.out_embed = nn.Embedding(sparse_dict[target_col], n_embed,\n",
    "                                      padding_idx=0 if padding else None)\n",
    "        self.attn_embed = nn.Embedding(sparse_dict[target_col], k_side+1, \n",
    "                                       padding_idx=0 if padding else None)\n",
    "        \n",
    "        # Initialize out embedding tables with uniform distribution\n",
    "        nn.init.normal_(self.out_embed.weight, mean=0, std=0.0001)\n",
    "        nn.init.normal_(self.attn_embed.weight, mean=0, std=0.0001)\n",
    "\n",
    "        if noise_dist is None:\n",
    "            # sampling words uniformly\n",
    "            self.noise_dist = torch.ones(self.n_vocab)\n",
    "        else:\n",
    "            self.noise_dist = noise_dist\n",
    "        self.noise_dist = self.noise_dist.to(device)\n",
    "\n",
    "    def forward_input(self, input_dict):\n",
    "        # return input vector embeddings\n",
    "        embed_lst = []\n",
    "        for col in self.features:\n",
    "            if col in input_dict:\n",
    "                input_vector = self.input_embedding_dict[col](input_dict[col])\n",
    "                embed_lst.append(input_vector)\n",
    "\n",
    "        batch_size = input_vector.shape[0]\n",
    "        # embeds => [batch_size, k_side+1, n_embed]\n",
    "        embeds = torch.cat(embed_lst, dim=1).reshape(batch_size, self.k_side+1, self.n_embed)\n",
    "        \n",
    "        # attation => [batch_size, k_side+1]\n",
    "        attn_w = self.attn_embed(input_dict[self.target_col])\n",
    "        attn_w = torch.exp(attn_w)\n",
    "        attn_s = torch.sum(attn_w, dim=1).reshape(-1, 1)\n",
    "        attn_w = (attn_w/attn_s).reshape(batch_size, 1, self.k_side+1) # 归一化\n",
    "        \n",
    "        # attw => [batch_size, 1, k_side+1]\n",
    "        # embeds => [batch_size, k_side+1, embed_size]\n",
    "        # matmul out => [batch_size, 1, embed_size]\n",
    "        input_vector = torch.matmul(attn_w, embeds).squeeze(1)\n",
    "        \n",
    "        return input_vector\n",
    "\n",
    "    def forward_output(self, output_words):\n",
    "        # return output vector embeddings \n",
    "        output_vector = self.out_embed(output_words)\n",
    "        return output_vector\n",
    "    \n",
    "    def forward_noise(self, batch_size, n_samples):\n",
    "        \"\"\"Generate noise vectors with shape [batch_size, n_samples, n_embed]\n",
    "        \"\"\"\n",
    "        # sample words from our noise distribution \n",
    "        noise_words = torch.multinomial(self.noise_dist, batch_size*n_samples, \n",
    "                                        replacement=True) + self.sample_word_offset\n",
    "        noise_vector = self.out_embed(noise_words).view(batch_size, n_samples, self.n_embed)\n",
    "        \n",
    "        return noise_vector\n",
    "    \n",
    "    def forward_cold(self, input_dict):\n",
    "        \"\"\"处理冷启动item，使用其side info Embedding的均值\n",
    "        \"\"\"\n",
    "        # return input vector embeddings\n",
    "        embed_lst = []\n",
    "        for col in self.features:\n",
    "            if col in input_dict:\n",
    "                input_vector = self.input_embedding_dict[col](input_dict[col])\n",
    "                embed_lst.append(input_vector)\n",
    "\n",
    "        batch_size = input_vector.shape[0]\n",
    "        # embeds => [batch_size, k_side, n_embed]\n",
    "        embeds = torch.cat(embed_lst, dim=1).reshape(batch_size, self.k_side, self.n_embed)\n",
    "    \n",
    "        return torch.mean(embeds, dim=1)\n",
    "\n",
    "\n",
    "class NegativeSamplingLoss(nn.Module):\n",
    "    \"\"\"这里用的是负对数似然, 而不是sampled softmax\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, input_vectors, output_vectors, noise_vectors):\n",
    "        batch_size, embed_size = input_vectors.shape\n",
    "        \n",
    "        # input vectors should be a batch of column vectors\n",
    "        input_vectors = input_vectors.view(batch_size, embed_size, 1)\n",
    "        \n",
    "        # output vectors should be a batch of row vectors\n",
    "        output_vectors = output_vectors.view(batch_size, 1, embed_size)\n",
    "        \n",
    "        # bmm = batch matrix multiplication\n",
    "        # target words log-sigmoid loss\n",
    "        out_loss = torch.bmm(output_vectors, input_vectors).sigmoid().log()\n",
    "        \n",
    "        # negative sampling words log-sigmoid loss\n",
    "        # negative words sigmoid optmize to small, thus here noise_vectors.neg()\n",
    "        noise_loss = torch.bmm(noise_vectors.neg(), input_vectors).sigmoid().log()\n",
    "        # sum the losses over the sample of noise vectors\n",
    "        noise_loss = noise_loss.squeeze().sum(1)\n",
    "        \n",
    "        # sum target and negative loss\n",
    "        return -(out_loss + noise_loss).mean()\n",
    "\n",
    "\n",
    "class TextData(Dataset):\n",
    "    def __init__(self, df, sparse_columns=['feedid','label','authorid','feed_machine_tag_tfidf_cls_32',\n",
    "                                           'feed_machine_kw_tfidf_cls_17'],\n",
    "                 varlen_sparse_columns=[], device='cpu'):\n",
    "        self.sparse_columns = sparse_columns\n",
    "        self.varlen_sparse_columns = varlen_sparse_columns\n",
    "        self.device = device\n",
    "        self.data = {\n",
    "            col:df[col].values for col in sparse_columns\n",
    "        }\n",
    "        if varlen_sparse_columns:\n",
    "            for col in varlen_sparse_columns:\n",
    "                self.data[col] = np.vstack(df[col].values)\n",
    "\n",
    "        self.data_num = len(df)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_num\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_dic = {}\n",
    "        for col in self.sparse_columns:\n",
    "            data_dic[col] = torch.tensor(self.data[col][idx]).long() #.to(self.device)\n",
    "        if self.varlen_sparse_columns:\n",
    "            for col in self.varlen_sparse_columns:\n",
    "                data_dic[col] = torch.tensor(self.data[col][idx, :]).long() #.to(self.device)\n",
    "\n",
    "        return data_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>label</th>\n",
       "      <th>brand</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21864</td>\n",
       "      <td>11800</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21864</td>\n",
       "      <td>28044</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sku_id  label  brand  shop_id  cate\n",
       "0   21864  11800   2347     4110     6\n",
       "1   21864  28044   2347     4110     6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pd.read_pickle(f'{DATA_PATH}/pairs.pkl')\n",
    "df_pair.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算负采样时候各个word的概率\n",
    "word_counts = pickle.load(open(f'{DATA_PATH}/word_counts.pkl', 'rb'))\n",
    "# 按label encoder 进行排序，因为需要跟后面Embedding table采样保持一致\n",
    "word_counts = sorted(word_counts, key=lambda x:x[0])\n",
    "counts = np.array([wc[1] for wc in word_counts])\n",
    "\n",
    "noise_dist = torch.from_numpy(counts**(0.75)/np.sum(counts**(0.75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sku_id': 33345, 'brand': 3663, 'shop_id': 4786, 'cate': 80}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 各个field的维度，包含padding index\n",
    "lbe_dict = pickle.load(open(f'{DATA_PATH}/label_dict.pkl', 'rb'))\n",
    "vocab_dict = {feat:len(lbe_dict[feat].classes_)+1 for feat in lbe_dict}\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/11/2021 15:18:51 - INFO - __main__ -   Epoch 1/10 Step 70 Loss = 2.9070849418640137\n",
      "08/11/2021 15:18:57 - INFO - __main__ -   Epoch 2/10 Step 70 Loss = 1.984291434288025\n",
      "08/11/2021 15:19:05 - INFO - __main__ -   Epoch 3/10 Step 70 Loss = 1.4065927267074585\n",
      "08/11/2021 15:19:11 - INFO - __main__ -   Epoch 4/10 Step 70 Loss = 1.060995101928711\n",
      "08/11/2021 15:19:18 - INFO - __main__ -   Epoch 5/10 Step 70 Loss = 0.8512248992919922\n",
      "08/11/2021 15:19:24 - INFO - __main__ -   Epoch 6/10 Step 70 Loss = 0.6837941408157349\n",
      "08/11/2021 15:19:31 - INFO - __main__ -   Epoch 7/10 Step 70 Loss = 0.6034356951713562\n",
      "08/11/2021 15:19:37 - INFO - __main__ -   Epoch 8/10 Step 70 Loss = 0.5155255198478699\n",
      "08/11/2021 15:19:44 - INFO - __main__ -   Epoch 9/10 Step 70 Loss = 0.46551644802093506\n",
      "08/11/2021 15:19:51 - INFO - __main__ -   Epoch 10/10 Step 70 Loss = 0.4440944194793701\n"
     ]
    }
   ],
   "source": [
    "device = 'gpu'\n",
    "if device=='gpu' and torch.cuda.is_available():\n",
    "    # print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "textdata = TextData(df_pair, sparse_columns=['sku_id','label','brand','shop_id','cate']) \n",
    "textloader = DataLoader(textdata,\n",
    "                        batch_size=10000,\n",
    "                        shuffle=True,\n",
    "                        num_workers=10,\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n",
    "\n",
    "embedding_dim = 128\n",
    "model = EGES(vocab_dict, n_embed=embedding_dim, k_side=3, target_col='sku_id',\n",
    "             noise_dist=noise_dist, device=device, padding=True).to(device)\n",
    "criterion = NegativeSamplingLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
    "\n",
    "epoch = 10\n",
    "for e in range(epoch):\n",
    "    for i, data_dic in enumerate(textloader):\n",
    "        # input, output and noise vectors\n",
    "        data_dic = {feat:data_dic[feat].to(device) for feat in data_dic}\n",
    "        input_vectors = model.forward_input(data_dic)\n",
    "        output_vectors = model.forward_output(data_dic['label'])\n",
    "        noise_vectors = model.forward_noise(data_dic['label'].shape[0], 10)\n",
    "        # negative sampling loss\n",
    "        loss = criterion(input_vectors, output_vectors, noise_vectors)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    logger.info(f'Epoch {e+1}/{epoch} Step {i} Loss = {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), f'{DATA_PATH}/model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推理得到各个item的Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32596, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>label</th>\n",
       "      <th>brand</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21864</td>\n",
       "      <td>11800</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11800</td>\n",
       "      <td>21864</td>\n",
       "      <td>748</td>\n",
       "      <td>1624</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sku_id  label  brand  shop_id  cate\n",
       "0   21864  11800   2347     4110     6\n",
       "2   11800  21864    748     1624     6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item = df_pair.drop_duplicates(subset=['sku_id'])\n",
    "print(df_item.shape)\n",
    "df_item.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata1 = textdata = TextData(df_item, sparse_columns=['sku_id','label','brand','shop_id','cate']) \n",
    "textloader1 = DataLoader(textdata1,\n",
    "                        batch_size=10000,\n",
    "                        shuffle=False,\n",
    "                        num_workers=10,\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n",
    "\n",
    "embedding_dim = 128\n",
    "model = EGES(vocab_dict, n_embed=embedding_dim, k_side=3, target_col='sku_id',\n",
    "             noise_dist=noise_dist, device=device, padding=True).to(device)\n",
    "state_dic = torch.load(f'{DATA_PATH}/model.bin')\n",
    "model.load_state_dict(state_dic)\n",
    "model = model.eval()\n",
    "\n",
    "epoch = 10\n",
    "emb_vectors = []\n",
    "with torch.no_grad():\n",
    "    for i, data_dic in enumerate(textloader1):\n",
    "        # input, output and noise vectors\n",
    "        data_dic = {feat:data_dic[feat].to(device) for feat in data_dic}\n",
    "        input_vectors = model.forward_input(data_dic)\n",
    "        emb_vectors.append(input_vectors.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_emb = dict(zip(df_item['sku_id'].tolist(), np.vstack(emb_vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32596"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推理冷启动item的Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item2 = df_pair[['brand','shop_id','cate']].head(10)\n",
    "textdata2 = textdata = TextData(df_item2, sparse_columns=['brand','shop_id','cate']) \n",
    "textloader2 = DataLoader(textdata2,\n",
    "                        batch_size=10000,\n",
    "                        shuffle=False,\n",
    "                        num_workers=10,\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n",
    "\n",
    "embedding_dim = 128\n",
    "model = EGES(vocab_dict, n_embed=embedding_dim, k_side=3, target_col='sku_id',\n",
    "             noise_dist=noise_dist, device=device, padding=True).to(device)\n",
    "state_dic = torch.load(f'{DATA_PATH}/model.bin')\n",
    "model.load_state_dict(state_dic)\n",
    "model = model.eval()\n",
    "\n",
    "epoch = 10\n",
    "cold_vectors = []\n",
    "with torch.no_grad():\n",
    "    for i, data_dic in enumerate(textloader2):\n",
    "        # input, output and noise vectors\n",
    "        data_dic = {feat:data_dic[feat].to(device) for feat in data_dic}\n",
    "        input_vectors = model.forward_cold(data_dic)\n",
    "        cold_vectors.append(input_vectors.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_emb = dict(zip(df_pair['sku_id'].head(10).tolist(), np.vstack(cold_vectors)))\n",
    "len(cold_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(cold_vectors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21864, 21864, 11800, 11800, 28044, 28044, 4215, 4215, 4215, 4215]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair['sku_id'].head(10).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_emb[21864].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(zip(df_pair['sku_id'].head(10).tolist(), np.vstack(cold_vectors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{21864: array([ 0.36127394,  0.6206276 ,  0.47120947,  0.3452674 ,  0.5544046 ,\n",
       "         0.4146522 ,  0.17631285, -0.24128747,  0.77740884, -0.08412822,\n",
       "        -0.36293218, -0.3261761 , -0.34041715, -0.15192428,  0.42707568,\n",
       "         0.80468315,  0.38587892,  0.43185422,  0.35225362, -0.3796761 ,\n",
       "        -0.25281656, -0.3164242 ,  0.3203004 ,  0.24328312,  0.39210245,\n",
       "         0.5225526 ,  0.58937246,  0.3025766 ,  0.0579358 , -0.39361346,\n",
       "        -0.3548419 ,  0.40479657, -0.46173054,  0.35296935, -0.0153293 ,\n",
       "         0.21133468, -0.31625533,  0.34576088,  0.7580024 , -0.23650432,\n",
       "        -0.3118156 , -0.05274419,  0.41590333,  0.14577492,  0.4472705 ,\n",
       "        -0.3095253 ,  0.21514341, -0.15776043,  0.3595067 ,  0.34932578,\n",
       "         0.4820422 , -0.51974714,  0.1711173 , -0.45721257, -0.27811825,\n",
       "         0.79957765,  0.22526991, -1.1348275 ,  0.04508468,  0.3154893 ,\n",
       "         1.063304  , -0.69589984, -0.15088998, -0.33925807,  0.05807626,\n",
       "        -0.6380265 , -0.12613311,  0.09695312, -0.28661227,  0.20314094,\n",
       "        -0.62328315, -0.2602175 ,  0.41935796,  0.1365327 ,  0.8690418 ,\n",
       "        -0.46920455,  0.2622699 ,  0.39084548,  0.05244987,  0.2638598 ,\n",
       "        -0.14778337, -0.30416656, -0.07794219, -0.18108508, -0.3962217 ,\n",
       "        -0.20603806,  0.3749768 ,  0.3806365 , -0.3711618 , -0.32104385,\n",
       "         0.39824748,  0.37328696,  1.0153533 ,  0.339133  , -0.3105423 ,\n",
       "        -0.2514749 , -0.15852502,  0.38235053, -0.367941  ,  0.20247082,\n",
       "        -0.7418203 ,  0.26964295, -0.4409837 , -0.26661274,  0.37359208,\n",
       "        -0.2603474 ,  0.315337  ,  0.49432015, -0.3811757 ,  0.03455855,\n",
       "         0.00757799,  0.6657254 , -0.1326074 ,  0.49935395, -0.01716162,\n",
       "         0.3842382 ,  0.27699143,  0.07680817, -0.39953285, -0.25202006,\n",
       "         0.19309661, -0.32875085, -0.463204  ,  0.27779868, -0.277225  ,\n",
       "         0.22354238,  0.40227646, -0.03466844], dtype=float32),\n",
       " 11800: array([ 0.48424911,  0.2761879 ,  0.607398  ,  0.5037737 , -0.16476253,\n",
       "        -0.16837367,  0.5857624 , -0.17302799,  0.2937218 , -0.51074237,\n",
       "        -0.5124083 ,  0.02911746, -0.37166888,  0.20932989, -0.15486574,\n",
       "        -0.32899022,  0.07110933,  0.16032642,  0.10853022, -0.18361884,\n",
       "        -0.2139455 ,  0.13621397, -0.06427768, -0.1864181 ,  0.18047974,\n",
       "        -0.02449579,  0.42750296,  0.02156426, -0.1846057 , -0.48221573,\n",
       "        -0.46398592,  0.18669844, -0.8617147 ,  0.15888053,  0.03588332,\n",
       "         0.34907123, -0.09216243,  0.3312568 , -0.02898549, -0.1268768 ,\n",
       "        -0.34522712, -0.500892  ,  0.13910082, -0.02870969,  0.57144433,\n",
       "        -0.45536405,  1.0655917 , -0.34465393,  0.2456153 ,  0.03208389,\n",
       "        -0.07777449, -0.847628  ,  0.24826431, -0.30076456, -0.16273306,\n",
       "        -0.10399301,  0.17358617, -1.1651157 ,  0.35834193, -0.2670394 ,\n",
       "         0.81100297, -0.58154327, -0.07821091, -0.4531859 ,  0.28628814,\n",
       "        -0.86449355, -0.507578  ,  0.20346388, -0.0737678 , -0.05100599,\n",
       "        -0.00163653,  0.08514537, -0.04227022,  0.31223977,  0.85448205,\n",
       "        -0.7380873 ,  0.7579403 ,  0.3487701 ,  0.2952581 , -0.5496268 ,\n",
       "        -0.2662322 , -0.45535177, -0.11124806,  0.48168707, -0.4304095 ,\n",
       "        -0.12086302,  0.25463194,  0.48348138, -0.10409103, -0.0784103 ,\n",
       "         0.50005317,  0.15825455,  0.6759546 ,  0.14155416, -0.21724467,\n",
       "        -0.44147798,  0.01489464,  0.11767441, -0.16349398,  0.2390049 ,\n",
       "        -0.95326585,  0.59600234, -0.12365668,  0.6227954 ,  0.25731036,\n",
       "        -0.79867995,  0.18012649,  0.3857836 , -0.4022511 , -0.6405073 ,\n",
       "         0.37070656,  0.6096597 ,  0.06112254,  0.2171632 ,  0.20061795,\n",
       "         0.37818098, -0.3093751 , -0.19526994, -0.19087403,  0.14338505,\n",
       "         0.24181871,  0.40422902,  0.14088991,  0.21874444, -0.3476605 ,\n",
       "         0.06800993,  0.35681957,  0.07740648], dtype=float32),\n",
       " 28044: array([ 0.48424911,  0.2761879 ,  0.607398  ,  0.5037737 , -0.16476253,\n",
       "        -0.16837367,  0.5857624 , -0.17302799,  0.2937218 , -0.51074237,\n",
       "        -0.5124083 ,  0.02911746, -0.37166888,  0.20932989, -0.15486574,\n",
       "        -0.32899022,  0.07110933,  0.16032642,  0.10853022, -0.18361884,\n",
       "        -0.2139455 ,  0.13621397, -0.06427768, -0.1864181 ,  0.18047974,\n",
       "        -0.02449579,  0.42750296,  0.02156426, -0.1846057 , -0.48221573,\n",
       "        -0.46398592,  0.18669844, -0.8617147 ,  0.15888053,  0.03588332,\n",
       "         0.34907123, -0.09216243,  0.3312568 , -0.02898549, -0.1268768 ,\n",
       "        -0.34522712, -0.500892  ,  0.13910082, -0.02870969,  0.57144433,\n",
       "        -0.45536405,  1.0655917 , -0.34465393,  0.2456153 ,  0.03208389,\n",
       "        -0.07777449, -0.847628  ,  0.24826431, -0.30076456, -0.16273306,\n",
       "        -0.10399301,  0.17358617, -1.1651157 ,  0.35834193, -0.2670394 ,\n",
       "         0.81100297, -0.58154327, -0.07821091, -0.4531859 ,  0.28628814,\n",
       "        -0.86449355, -0.507578  ,  0.20346388, -0.0737678 , -0.05100599,\n",
       "        -0.00163653,  0.08514537, -0.04227022,  0.31223977,  0.85448205,\n",
       "        -0.7380873 ,  0.7579403 ,  0.3487701 ,  0.2952581 , -0.5496268 ,\n",
       "        -0.2662322 , -0.45535177, -0.11124806,  0.48168707, -0.4304095 ,\n",
       "        -0.12086302,  0.25463194,  0.48348138, -0.10409103, -0.0784103 ,\n",
       "         0.50005317,  0.15825455,  0.6759546 ,  0.14155416, -0.21724467,\n",
       "        -0.44147798,  0.01489464,  0.11767441, -0.16349398,  0.2390049 ,\n",
       "        -0.95326585,  0.59600234, -0.12365668,  0.6227954 ,  0.25731036,\n",
       "        -0.79867995,  0.18012649,  0.3857836 , -0.4022511 , -0.6405073 ,\n",
       "         0.37070656,  0.6096597 ,  0.06112254,  0.2171632 ,  0.20061795,\n",
       "         0.37818098, -0.3093751 , -0.19526994, -0.19087403,  0.14338505,\n",
       "         0.24181871,  0.40422902,  0.14088991,  0.21874444, -0.3476605 ,\n",
       "         0.06800993,  0.35681957,  0.07740648], dtype=float32),\n",
       " 4215: array([ 0.51205516,  1.4748939 ,  0.7803833 ,  0.2848904 ,  0.45226166,\n",
       "         0.46994528,  1.2152088 , -0.64014137, -0.6402718 ,  0.6056917 ,\n",
       "         0.32332462, -0.43436742, -0.4067477 , -0.5736462 , -0.30770418,\n",
       "         0.5460741 ,  0.10788976,  0.5600059 , -0.00691355, -0.36143148,\n",
       "        -0.39390695,  0.05378624,  0.51801574,  0.48668513,  0.34276745,\n",
       "         0.5268663 ,  0.91629   ,  0.20845115,  0.19894403, -0.03537949,\n",
       "        -0.14050862, -0.0027012 , -0.19876938,  0.5989167 , -0.40201223,\n",
       "         0.57035774, -0.37479016,  0.15558545, -0.30542892,  0.12691809,\n",
       "        -0.31218508, -0.7495035 ,  0.45154247,  0.04067433,  0.11370446,\n",
       "        -0.9884248 ,  0.78491515,  0.0227289 ,  0.49531454,  0.5201844 ,\n",
       "         0.53536165, -0.8004998 ,  0.2768484 , -0.3373172 , -0.2765632 ,\n",
       "         0.5240769 ,  0.06203198,  0.74990433,  1.3049871 ,  0.17587905,\n",
       "        -0.76345694, -1.0336169 , -0.32481542,  0.7983118 ,  0.29185313,\n",
       "        -0.2080631 , -0.90105504,  0.0157572 , -0.3084528 ,  0.59274405,\n",
       "        -0.45765692,  0.43134508, -0.46203884,  0.2358145 , -0.5418618 ,\n",
       "        -0.67203826,  0.50526637,  0.46912783,  0.03789499, -0.23737983,\n",
       "        -0.12133458,  0.07378417,  0.11880475, -0.12356185, -0.21954751,\n",
       "        -0.3432865 ,  0.502342  ,  0.48160562, -0.49864143,  1.3319205 ,\n",
       "        -0.00491425,  0.3279271 ,  0.07629625,  0.23811111, -0.27934134,\n",
       "         0.22747116, -0.37523445,  0.55057687, -0.140147  ,  0.6573767 ,\n",
       "        -0.61184216,  0.65979475,  0.04270354,  1.3953632 ,  0.32815143,\n",
       "         0.15064839,  0.46824908,  0.27333236, -0.45549792, -0.5841508 ,\n",
       "         0.05634561,  0.04339457, -0.39598274,  0.65744686,  0.15764871,\n",
       "         0.14749765, -0.8819933 ,  0.94665813, -0.67505586, -0.6172205 ,\n",
       "         0.08764982, -0.70669544, -0.08999189, -0.6841363 ,  1.0985391 ,\n",
       "        -0.22701088,  0.5714152 ,  0.52142346], dtype=float32)}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(df_pair['sku_id'].head(10).tolist(), np.vstack(cold_vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
