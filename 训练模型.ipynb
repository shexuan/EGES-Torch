{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data_cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(sparse_columns, varlen_sparse_columns, embed_dim,\n",
    "                            init_std=0.0001, padding=True, device='cpu', mode='mean'):\n",
    "    # sparse_columns => dict{'name':vocab_size}\n",
    "    # Return nn.ModuleDict: for sparse features, {embedding_name: nn.Embedding}\n",
    "    padding_idx = 0 if padding else None\n",
    "    sparse_embedding_dict = {\n",
    "        feat: nn.Embedding(sparse_columns[feat], embed_dim, padding_idx=padding_idx)\n",
    "                             for feat in sparse_columns\n",
    "    }\n",
    "    \n",
    "    if varlen_sparse_columns:\n",
    "        varlen_sparse_embedding_dict = {\n",
    "            feat:nn.EmbeddingBag(varlen_sparse_columns[feat], embed_dim, padding_idx=padding_idx,\n",
    "                                 mode=mode) for feat in varlen_sparse_columns\n",
    "        }\n",
    "        sparse_embedding_dict.update(varlen_sparse_embedding_dict)\n",
    "        \n",
    "    embedding_dict = nn.ModuleDict(sparse_embedding_dict)\n",
    "    \n",
    "    for tensor in embedding_dict.values():\n",
    "        nn.init.normal_(tensor.weight, mean=0, std=init_std)\n",
    "        # nn.init.kaiming_uniform_(tensor.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    return embedding_dict.to(device)\n",
    "\n",
    "\n",
    "class EGES(nn.Module):\n",
    "    def __init__(self, sparse_dict, varlen_sparse_dict=None, target_col='sku_id',\n",
    "                 n_embed=64, k_side=3, noise_dist=None, device='cpu', padding=True):\n",
    "        \"\"\"sparse_dict: dict, {feature_name: vocab_size}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_embed = n_embed\n",
    "        self.k_side = k_side\n",
    "        self.device = device\n",
    "        self.padding = padding\n",
    "        self.target_col = target_col\n",
    "        self.features = list(sparse_dict.keys())\n",
    "        if varlen_sparse_dict:\n",
    "            self.features = self.features + list(varlen_sparse_dict.keys())\n",
    "        # 如果padding了的话，则负采样出来的index均需要+1\n",
    "        self.sample_word_offset = 1 if padding else 0\n",
    "        # input embedding dict, include item and side info\n",
    "        self.input_embedding_dict = create_embedding_matrix(\n",
    "            sparse_dict, varlen_sparse_dict, n_embed,\n",
    "            init_std=0.0001, padding=padding, device=device, mode='mean')\n",
    "        self.out_embed = nn.Embedding(sparse_dict[target_col], n_embed,\n",
    "                                      padding_idx=0 if padding else None)\n",
    "        self.attn_embed = nn.Embedding(sparse_dict[target_col], k_side+1, \n",
    "                                       padding_idx=0 if padding else None)\n",
    "        \n",
    "        # Initialize out embedding tables with uniform distribution\n",
    "        nn.init.normal_(self.out_embed.weight, mean=0, std=0.0001)\n",
    "        nn.init.normal_(self.attn_embed.weight, mean=0, std=0.0001)\n",
    "\n",
    "        if noise_dist is None:\n",
    "            # sampling words uniformly\n",
    "            self.noise_dist = torch.ones(self.n_vocab)\n",
    "        else:\n",
    "            self.noise_dist = noise_dist\n",
    "        self.noise_dist = self.noise_dist.to(device)\n",
    "\n",
    "    def forward_input(self, input_dict):\n",
    "        # return input vector embeddings\n",
    "        embed_lst = []\n",
    "        for col in self.features:\n",
    "            if col in input_dict:\n",
    "                input_vector = self.input_embedding_dict[col](input_dict[col])\n",
    "                embed_lst.append(input_vector)\n",
    "\n",
    "        batch_size = input_vector.shape[0]\n",
    "        # embeds => [batch_size, k_side+1, n_embed]\n",
    "        embeds = torch.cat(embed_lst, dim=1).reshape(batch_size, self.k_side+1, self.n_embed)\n",
    "        \n",
    "        # attation => [batch_size, k_side+1]\n",
    "        attn_w = self.attn_embed(input_dict[self.target_col])\n",
    "        attn_w = torch.exp(attn_w)\n",
    "        attn_s = torch.sum(attn_w, dim=1).reshape(-1, 1)\n",
    "        attn_w = (attn_w/attn_s).reshape(batch_size, 1, self.k_side+1) # 归一化\n",
    "        \n",
    "        # attw => [batch_size, 1, k_side+1]\n",
    "        # embeds => [batch_size, k_side+1, embed_size]\n",
    "        # matmul out => [batch_size, 1, embed_size]\n",
    "        input_vector = torch.matmul(attn_w, embeds).squeeze(1)\n",
    "        \n",
    "        return input_vector\n",
    "\n",
    "    def forward_output(self, output_words):\n",
    "        # return output vector embeddings \n",
    "        output_vector = self.out_embed(output_words)\n",
    "        return output_vector\n",
    "    \n",
    "    def forward_noise(self, batch_size, n_samples):\n",
    "        \"\"\"Generate noise vectors with shape [batch_size, n_samples, n_embed]\n",
    "        \"\"\"\n",
    "        # sample words from our noise distribution \n",
    "        noise_words = torch.multinomial(self.noise_dist, batch_size*n_samples, \n",
    "                                        replacement=True) + self.sample_word_offset\n",
    "        noise_vector = self.out_embed(noise_words).view(batch_size, n_samples, self.n_embed)\n",
    "        \n",
    "        return noise_vector\n",
    "    \n",
    "    def forward_cold(self, input_dict):\n",
    "        \"\"\"处理冷启动item，使用其side info Embedding的均值\n",
    "        \"\"\"\n",
    "        # return input vector embeddings\n",
    "        embed_lst = []\n",
    "        for col in self.features:\n",
    "            if col in input_dict:\n",
    "                input_vector = self.input_embedding_dict[col](input_dict[col])\n",
    "                embed_lst.append(input_vector)\n",
    "\n",
    "        batch_size = input_vector.shape[0]\n",
    "        # embeds => [batch_size, k_side, n_embed]\n",
    "        embeds = torch.cat(embed_lst, dim=1).reshape(batch_size, self.k_side, self.n_embed)\n",
    "        return torch.mean(embeds, dim=1)\n",
    "\n",
    "\n",
    "class NegativeSamplingLoss(nn.Module):\n",
    "    \"\"\"这里用的是负对数似然, 而不是sampled softmax\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, input_vectors, output_vectors, noise_vectors):\n",
    "        batch_size, embed_size = input_vectors.shape\n",
    "        \n",
    "        # input vectors should be a batch of column vectors\n",
    "        input_vectors = input_vectors.view(batch_size, embed_size, 1)\n",
    "        \n",
    "        # output vectors should be a batch of row vectors\n",
    "        output_vectors = output_vectors.view(batch_size, 1, embed_size)\n",
    "        \n",
    "        # bmm = batch matrix multiplication\n",
    "        # target words log-sigmoid loss\n",
    "        out_loss = torch.bmm(output_vectors, input_vectors).sigmoid().log()\n",
    "        \n",
    "        # negative sampling words log-sigmoid loss\n",
    "        # negative words sigmoid optmize to small, thus here noise_vectors.neg()\n",
    "        noise_loss = torch.bmm(noise_vectors.neg(), input_vectors).sigmoid().log()\n",
    "        # sum the losses over the sample of noise vectors\n",
    "        noise_loss = noise_loss.squeeze().sum(1)\n",
    "        \n",
    "        # sum target and negative loss\n",
    "        return -(out_loss + noise_loss).mean()\n",
    "\n",
    "\n",
    "class TextData(Dataset):\n",
    "    def __init__(self, df, sparse_columns=['feedid','label','authorid','feed_machine_tag_tfidf_cls_32',\n",
    "                                           'feed_machine_kw_tfidf_cls_17'],\n",
    "                 varlen_sparse_columns=[], device='cpu'):\n",
    "        self.sparse_columns = sparse_columns\n",
    "        self.varlen_sparse_columns = varlen_sparse_columns\n",
    "        self.device = device\n",
    "        self.data = {\n",
    "            col:df[col].values for col in sparse_columns\n",
    "        }\n",
    "        if varlen_sparse_columns:\n",
    "            for col in varlen_sparse_columns:\n",
    "                self.data[col] = np.vstack(df[col].values)\n",
    "\n",
    "        self.data_num = len(df)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_num\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_dic = {}\n",
    "        for col in self.sparse_columns:\n",
    "            data_dic[col] = torch.tensor(self.data[col][idx]).long() #.to(self.device)\n",
    "        if self.varlen_sparse_columns:\n",
    "            for col in self.varlen_sparse_columns:\n",
    "                data_dic[col] = torch.tensor(self.data[col][idx, :]).long() #.to(self.device)\n",
    "\n",
    "        return data_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>label</th>\n",
       "      <th>brand</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21864</td>\n",
       "      <td>11800</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21864</td>\n",
       "      <td>28044</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sku_id  label  brand  shop_id  cate\n",
       "0   21864  11800   2347     4110     6\n",
       "1   21864  28044   2347     4110     6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pd.read_pickle(f'{DATA_PATH}/pairs.pkl')\n",
    "df_pair.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算负采样时候各个word的概率\n",
    "word_counts = pickle.load(open(f'{DATA_PATH}/word_counts.pkl', 'rb'))\n",
    "# 按label encoder 进行排序，因为需要跟后面Embedding table采样保持一致\n",
    "word_counts = sorted(word_counts, key=lambda x:x[0])\n",
    "counts = np.array([wc[1] for wc in word_counts])\n",
    "\n",
    "noise_dist = torch.from_numpy(counts**(0.75)/np.sum(counts**(0.75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sku_id': 33345, 'brand': 3663, 'shop_id': 4786, 'cate': 80}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 各个field的维度，包含padding index\n",
    "lbe_dict = pickle.load(open(f'{DATA_PATH}/label_dict.pkl', 'rb'))\n",
    "vocab_dict = {feat:len(lbe_dict[feat].classes_)+1 for feat in lbe_dict}\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/11/2021 15:18:51 - INFO - __main__ -   Epoch 1/10 Step 70 Loss = 2.9070849418640137\n",
      "08/11/2021 15:18:57 - INFO - __main__ -   Epoch 2/10 Step 70 Loss = 1.984291434288025\n",
      "08/11/2021 15:19:05 - INFO - __main__ -   Epoch 3/10 Step 70 Loss = 1.4065927267074585\n",
      "08/11/2021 15:19:11 - INFO - __main__ -   Epoch 4/10 Step 70 Loss = 1.060995101928711\n",
      "08/11/2021 15:19:18 - INFO - __main__ -   Epoch 5/10 Step 70 Loss = 0.8512248992919922\n",
      "08/11/2021 15:19:24 - INFO - __main__ -   Epoch 6/10 Step 70 Loss = 0.6837941408157349\n",
      "08/11/2021 15:19:31 - INFO - __main__ -   Epoch 7/10 Step 70 Loss = 0.6034356951713562\n",
      "08/11/2021 15:19:37 - INFO - __main__ -   Epoch 8/10 Step 70 Loss = 0.5155255198478699\n",
      "08/11/2021 15:19:44 - INFO - __main__ -   Epoch 9/10 Step 70 Loss = 0.46551644802093506\n",
      "08/11/2021 15:19:51 - INFO - __main__ -   Epoch 10/10 Step 70 Loss = 0.4440944194793701\n"
     ]
    }
   ],
   "source": [
    "device = 'gpu'\n",
    "if device=='gpu' and torch.cuda.is_available():\n",
    "    # print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "textdata = TextData(df_pair, sparse_columns=['sku_id','label','brand','shop_id','cate']) \n",
    "textloader = DataLoader(textdata,\n",
    "                        batch_size=10000,\n",
    "                        shuffle=True,\n",
    "                        num_workers=10,\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n",
    "\n",
    "embedding_dim = 128\n",
    "model = EGES(vocab_dict, n_embed=embedding_dim, k_side=3, target_col='sku_id',\n",
    "             noise_dist=noise_dist, device=device, padding=True).to(device)\n",
    "criterion = NegativeSamplingLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
    "\n",
    "epoch = 10\n",
    "for e in range(epoch):\n",
    "    for i, data_dic in enumerate(textloader):\n",
    "        # input, output and noise vectors\n",
    "        data_dic = {feat:data_dic[feat].to(device) for feat in data_dic}\n",
    "        input_vectors = model.forward_input(data_dic)\n",
    "        output_vectors = model.forward_output(data_dic['label'])\n",
    "        noise_vectors = model.forward_noise(data_dic['label'].shape[0], 10)\n",
    "        # negative sampling loss\n",
    "        loss = criterion(input_vectors, output_vectors, noise_vectors)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    logger.info(f'Epoch {e+1}/{epoch} Step {i} Loss = {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), f'{DATA_PATH}/model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推理得到各个item的Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32596, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>label</th>\n",
       "      <th>brand</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21864</td>\n",
       "      <td>11800</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11800</td>\n",
       "      <td>21864</td>\n",
       "      <td>748</td>\n",
       "      <td>1624</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sku_id  label  brand  shop_id  cate\n",
       "0   21864  11800   2347     4110     6\n",
       "1   11800  21864    748     1624     6"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item = df_pair.drop_duplicates(subset=['sku_id']).reset_index(drop=True)\n",
    "print(df_item.shape)\n",
    "df_item.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata1 = textdata = TextData(df_item, sparse_columns=['sku_id','label','brand','shop_id','cate']) \n",
    "textloader1 = DataLoader(textdata1,\n",
    "                        batch_size=10000,\n",
    "                        shuffle=False,\n",
    "                        num_workers=10,\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n",
    "\n",
    "embedding_dim = 128\n",
    "model = EGES(vocab_dict, n_embed=embedding_dim, k_side=3, target_col='sku_id',\n",
    "             noise_dist=noise_dist, device=device, padding=True).to(device)\n",
    "state_dic = torch.load(f'{DATA_PATH}/model.bin')\n",
    "model.load_state_dict(state_dic)\n",
    "model = model.eval()\n",
    "\n",
    "epoch = 10\n",
    "emb_vectors = []\n",
    "with torch.no_grad():\n",
    "    for i, data_dic in enumerate(textloader1):\n",
    "        # input, output and noise vectors\n",
    "        data_dic = {feat:data_dic[feat].to(device) for feat in data_dic}\n",
    "        input_vectors = model.forward_input(data_dic)\n",
    "        emb_vectors.append(input_vectors.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_emb = dict(zip(df_item['sku_id'].tolist(), np.vstack(emb_vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32596"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_emb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推理冷启动item的Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item2 = df_pair.drop_duplicates(subset=['sku_id'])[['brand','shop_id','cate']].head(10)\n",
    "textdata2 = textdata = TextData(df_item2, sparse_columns=['brand','shop_id','cate']) \n",
    "textloader2 = DataLoader(textdata2,\n",
    "                        batch_size=10000,\n",
    "                        shuffle=False,\n",
    "                        num_workers=10,\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n",
    "\n",
    "embedding_dim = 128\n",
    "model = EGES(vocab_dict, n_embed=embedding_dim, k_side=3, target_col='sku_id',\n",
    "             noise_dist=noise_dist, device=device, padding=True).to(device)\n",
    "state_dic = torch.load(f'{DATA_PATH}/model.bin')\n",
    "model.load_state_dict(state_dic)\n",
    "model = model.eval()\n",
    "\n",
    "epoch = 10\n",
    "cold_vectors = []\n",
    "with torch.no_grad():\n",
    "    for i, data_dic in enumerate(textloader2):\n",
    "        # input, output and noise vectors\n",
    "        data_dic = {feat:data_dic[feat].to(device) for feat in data_dic}\n",
    "        input_vectors = model.forward_cold(data_dic)\n",
    "        cold_vectors.append(input_vectors.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_emb = dict(zip(df_pair.drop_duplicates(subset=['sku_id'])['sku_id'].head(10).tolist(), np.vstack(cold_vectors)))\n",
    "len(cold_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([21864, 11800, 28044, 4215, 31898, 8519, 21941, 14684, 2970, 11007])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_emb.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看冷启动方式得到的Embedding与原Embedding的相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>label</th>\n",
       "      <th>brand</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21864</td>\n",
       "      <td>11800</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11800</td>\n",
       "      <td>21864</td>\n",
       "      <td>748</td>\n",
       "      <td>1624</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sku_id  label  brand  shop_id  cate\n",
       "0   21864  11800   2347     4110     6\n",
       "1   11800  21864    748     1624     6"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23870, 0.9760314),\n",
       " (1909, 0.9652012),\n",
       " (19325, 0.9550275),\n",
       " (4071, 0.95498335),\n",
       " (10087, 0.9508642)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim1 = cosine_similarity(cold_emb[21864].reshape(1,-1), np.vstack(emb_vectors))\n",
    "sim11 = list(zip(df_item['sku_id'].tolist(), sim1[0]))\n",
    "sim11 = sorted(sim11, key=lambda x:x[1], reverse=True)\n",
    "sim11[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>label</th>\n",
       "      <th>brand</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28829</th>\n",
       "      <td>23870</td>\n",
       "      <td>24721</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku_id  label  brand  shop_id  cate\n",
       "28829   23870  24721   2347     4110     6"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item.query('sku_id==23870')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>label</th>\n",
       "      <th>brand</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21864</td>\n",
       "      <td>11800</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>12520</td>\n",
       "      <td>2793</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2793</td>\n",
       "      <td>12520</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>18844</td>\n",
       "      <td>19808</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>3126</td>\n",
       "      <td>19808</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sku_id  label  brand  shop_id  cate\n",
       "0     21864  11800   2347     4110     6\n",
       "108   12520   2793   2347     4110     6\n",
       "109    2793  12520   2347     4110     6\n",
       "530   18844  19808   2347     4110     6\n",
       "531    3126  19808   2347     4110     6"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item.query('(brand==2347)&(shop_id==4110)&(cate==6)').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>label</th>\n",
       "      <th>brand</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21864</td>\n",
       "      <td>11800</td>\n",
       "      <td>2347</td>\n",
       "      <td>4110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11800</td>\n",
       "      <td>21864</td>\n",
       "      <td>748</td>\n",
       "      <td>1624</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sku_id  label  brand  shop_id  cate\n",
       "0   21864  11800   2347     4110     6\n",
       "1   11800  21864    748     1624     6"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21864, 1.0),\n",
       " (22840, 0.8361774),\n",
       " (12176, 0.8087917),\n",
       " (3813, 0.80076164),\n",
       " (13764, 0.764928)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim2 = cosine_similarity(vocab_emb[21864].reshape(1,-1), np.vstack(emb_vectors))\n",
    "sim22 = list(zip(df_item['sku_id'].tolist(), sim2[0]))\n",
    "sim22 = sorted(sim22, key=lambda x:x[1], reverse=True)\n",
    "sim22[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>label</th>\n",
       "      <th>brand</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23867</th>\n",
       "      <td>22840</td>\n",
       "      <td>21864</td>\n",
       "      <td>3101</td>\n",
       "      <td>3000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku_id  label  brand  shop_id  cate\n",
       "23867   22840  21864   3101     3000     6"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item.query('sku_id==22840')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59903204]], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 原Embedding与cold Embedding最相似的word的相似度\n",
    "# 相似度排名大概在100多（总32596）\n",
    "cosine_similarity(vocab_emb[21864].reshape(1,-1), vocab_emb[23870].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7097324]], dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cold Embedding与原Embedding 最相似的word的相似度\n",
    "cosine_similarity(cold_emb[21864].reshape(1,-1), vocab_emb[22840].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6926477]], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(vocab_emb[23870].reshape(1,-1), vocab_emb[22840].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
